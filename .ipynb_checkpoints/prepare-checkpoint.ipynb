{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import newspaper\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import import_ipynb\n",
    "from news_classes import *\n",
    "from tqdm import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class collector:\n",
    "    def prepare_news():\n",
    "        urls=[]\n",
    "        urls.append(\"https://www.thedailystar.net/\")\n",
    "        urls.append(\"http://www.observerbd.com/\")\n",
    "        urls.append(\"https://bdnews24.com/\")\n",
    "        urls.append(\"https://en.prothomalo.com/\")\n",
    "        urls.append(\"https://www.clickittefaq.com/\")\n",
    "        urls.append(\"http://english.kalerkantho.com/\")\n",
    "\n",
    "        papers_today = []\n",
    "        for url in tq(urls):\n",
    "            papers_today.append(newspaper.build(url,  memoize_articles=False))\n",
    "            print(url)\n",
    "\n",
    "        cwd=os.getcwd()+'/'\n",
    "        now = datetime.now()\n",
    "        #paper_path = \"news_\"+str(now.day)+\"_\"+str(now.month)+\"_\"+str(now.year)+\".pkl\"\n",
    "        paper_path = \"news_today.pkl\"\n",
    "\n",
    "        myPaper = customizedPaper()\n",
    "\n",
    "        cnt = 0 \n",
    "        for paper in tq(papers_today):\n",
    "            for article in tq(paper.articles):\n",
    "                try:\n",
    "                    article.download() \n",
    "                    article.parse() \n",
    "\n",
    "                    temp_article=paragraph(article.title, article.url, article.text, article.publish_date, paper.brand) \n",
    "                    myPaper.addParagraph(temp_article)\n",
    "                except:\n",
    "                    None\n",
    "\n",
    "        with open(paper_path, 'wb') as output:\n",
    "            pickle.dump(myPaper, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(paper_path, 'rb') as input:\n",
    "            tnews = pickle.load(input)\n",
    "\n",
    "        cnt=0\n",
    "        for mmm in tnews.paragraphs:\n",
    "            if mmm is not None:\n",
    "                cnt=cnt+1\n",
    "        print(cnt)\n",
    "\n",
    "\n",
    "    def prepare_idf():\n",
    "        cwd=os.getcwd()+'/'\n",
    "        now = datetime.now()\n",
    "        paper_path = \"news_today.pkl\"\n",
    "        idf_path = \"idf_path.pkl\"\n",
    "\n",
    "        with open(paper_path, 'rb') as input:\n",
    "            allnews = pickle.load(input)\n",
    "\n",
    "        word_bob_list = []\n",
    "        for news in tq(allnews.paragraphs):\n",
    "            word_bob_list.append(tb(news.body).lower())\n",
    "\n",
    "        word_set = set()\n",
    "        for blob in tq(word_bob_list):\n",
    "            for word in blob.words:\n",
    "                word_set.add(str(word))\n",
    "\n",
    "        idf_count={}\n",
    "        for word in tq(word_set):\n",
    "            for blob in word_bob_list:\n",
    "                if(word in blob.words):\n",
    "                    if(word in idf_count.keys()):\n",
    "                        idf_count[word]+=1\n",
    "                    else:\n",
    "                        idf_count[word]=1\n",
    "\n",
    "        idfblob = idfBlob(idf_count, len(allnews.paragraphs))\n",
    "\n",
    "        with open(idf_path, 'wb') as output:\n",
    "            pickle.dump(idfblob, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_idf():\n",
    "    cwd=os.getcwd()+'/'\n",
    "    now = datetime.now()\n",
    "    paper_path = \"files/news_today.pkl\"\n",
    "    idf_path = \"files/idf_today.pkl\"\n",
    "\n",
    "    with open(paper_path, 'rb') as input:\n",
    "        allnews = pickle.load(input)\n",
    "\n",
    "    word_bob_list = []\n",
    "    for news in tq(allnews.paragraphs):\n",
    "        word_bob_list.append(tb(news.body).lower())\n",
    "\n",
    "    word_set = set()\n",
    "    for blob in tq(word_bob_list):\n",
    "        for word in blob.words:\n",
    "            word_set.add(str(word))\n",
    "\n",
    "    idf_count={}\n",
    "    for word in tq(word_set):\n",
    "        for blob in word_bob_list:\n",
    "            if(word in blob.words):\n",
    "                if(word in idf_count.keys()):\n",
    "                    idf_count[word]+=1\n",
    "                else:\n",
    "                    idf_count[word]=1\n",
    "\n",
    "    idfblob = idfBlob(idf_count, len(allnews.paragraphs))\n",
    "\n",
    "    with open(idf_path, 'wb') as output:\n",
    "        pickle.dump(idfblob, output, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
